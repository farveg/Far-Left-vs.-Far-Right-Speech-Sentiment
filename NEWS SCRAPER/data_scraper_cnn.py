# -*- coding: utf-8 -*-
"""Data_Scraper_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i9rcn9D-wFIpCo4aHMIxbkLY8VsQt6mH
"""

! pip install newscatcherapi
from newscatcherapi import NewsCatcherApiClient
import csv
import time
import os.path
import shutil
import re

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/Fox Summary

#with open(pathway, "r") as tf:
#    CNNBiden.append(tf)

#for line in lines:
  #  print(line)
#re.split('; |, |\*|\n',a)

newscatcherapi = NewsCatcherApiClient(x_api_key='EcTsDEjSjLEk46mk6G9XBcFWXKVIBBHi2Lfocq7IYs4')

all_articles = newscatcherapi.get_search(q='Biden',
                                         lang='en',
                                         sources= "cnn.com",
                                         page_size=10)

count = 0
articles = all_articles['articles']
for article in articles[:10]:   
    count+=1
    print(str(count) + ". " 
    + "\n\t\t" + article["summary"]\
    + "\n\n",
    file=open("CNN_Biden.text", 'a'))
    time.sleep(0.33)

newscatcherapi = NewsCatcherApiClient(x_api_key='EcTsDEjSjLEk46mk6G9XBcFWXKVIBBHi2Lfocq7IYs4')

all_articles = newscatcherapi.get_search(q='Trump',
                                         lang='en',
                                         sources= "cnn.com",
                                         page_size=10)

count = 0
articles = all_articles['articles']
for article in articles[:10]:   
    count+=1
    print(str(count) + ". " 
    + "\n\t\t" + article["summary"]\
    + "\n\n",
    file=open("CNN_Trump-.txt", "a"))
    time.sleep(0.33)

newscatcherapi = NewsCatcherApiClient(x_api_key='EcTsDEjSjLEk46mk6G9XBcFWXKVIBBHi2Lfocq7IYs4')

all_articles = newscatcherapi.get_search(q='pandemic',
                                         lang='en',
                                         sources= "cnn.com",
                                         page_size=10)

count = 0
articles = all_articles['articles']
for article in articles[:10]:   
    count+=1
    print(str(count) + ". " 
    + "\n\t\t" + article["summary"]\
    + "\n\n",
    file=open("CNN-pandemic.txt", "a"))
    time.sleep(0.33)

newscatcherapi = NewsCatcherApiClient(x_api_key='EcTsDEjSjLEk46mk6G9XBcFWXKVIBBHi2Lfocq7IYs4')

all_articles = newscatcherapi.get_search(q='vaccine',
                                         lang='en',
                                         sources= "cnn.com",
                                         page_size=10)

count = 0
articles = all_articles['articles']
for article in articles[:10]:   
    count+=1
    print(str(count) + ". " 
    + "\n\t\t" + article["summary"]\
    + "\n\n",
    file=open("CNN_Vaccine.txt", "a"))
    time.sleep(0.33)

newscatcherapi = NewsCatcherApiClient(x_api_key='EcTsDEjSjLEk46mk6G9XBcFWXKVIBBHi2Lfocq7IYs4')

all_articles = newscatcherapi.get_search(q='Ukraine',
                                         lang='en',
                                         sources= "cnn.com",
                                         page_size=10)

count = 0
articles = all_articles['articles']
for article in articles[:10]:   
    count+=1
    print(str(count) + ". " 
    + "\n\t\t" + article["summary"]\
    + "\n\n",
    file=open("CNN_Ukraine.txt", "a"))
    time.sleep(0.33)

newscatcherapi = NewsCatcherApiClient(x_api_key='EcTsDEjSjLEk46mk6G9XBcFWXKVIBBHi2Lfocq7IYs4')

all_articles = newscatcherapi.get_search(q='Protest',
                                         lang='en',
                                         sources= "cnn.com",
                                         page_size=10)

count = 0
articles = all_articles['articles']
for article in articles[:10]:   
    count+=1
    print(str(count) + ". " 
    + "\n\t\t" + article["summary"]\
    + "\n\n",
    file=open("CNN_Protest.txt", "a"))
    time.sleep(0.33)

newscatcherapi = NewsCatcherApiClient(x_api_key='EcTsDEjSjLEk46mk6G9XBcFWXKVIBBHi2Lfocq7IYs4')

all_articles = newscatcherapi.get_search(q='Democrat',
                                         lang='en',
                                         sources= "cnn.com",
                                         page_size=10)

count = 0
articles = all_articles['articles']
for article in articles[:10]:   
    count+=1
    print(str(count) + ". " 
    + "\n\t\t" + article["summary"]\
    + "\n\n",
    file=open("CNN_Democrat.txt", "a"))
    time.sleep(0.33)

newscatcherapi = NewsCatcherApiClient(x_api_key='EcTsDEjSjLEk46mk6G9XBcFWXKVIBBHi2Lfocq7IYs4')

all_articles = newscatcherapi.get_search(q='Inflation',
                                         lang='en',
                                         sources= "cnn.com",
                                         page_size=10)

count = 0
articles = all_articles['articles']
for article in articles[:10]:   
    count+=1
    print(str(count) + ". " 
    + "\n\t\t" + article["summary"]\
    + "\n\n",
    file=open("CNN_Inflation.txt", "a"))
    time.sleep(0.33)

newscatcherapi = NewsCatcherApiClient(x_api_key='EcTsDEjSjLEk46mk6G9XBcFWXKVIBBHi2Lfocq7IYs4')

all_articles = newscatcherapi.get_search(q='Republican',
                                         lang='en',
                                         sources= "cnn.com",
                                         page_size=10)

count = 0
articles = all_articles['articles']
for article in articles[:10]:   
    count+=1
    print(str(count) + ". " 
    + "\n\t\t" + article["summary"]\
    + "\n\n",
    file=open("CNN_Republican.txt", "a"))
    time.sleep(0.33)

newscatcherapi = NewsCatcherApiClient(x_api_key='EcTsDEjSjLEk46mk6G9XBcFWXKVIBBHi2Lfocq7IYs4')

all_articles = newscatcherapi.get_search(q='Election',
                                         lang='en',
                                         sources= "cnn.com",
                                         page_size=10)

count = 0
articles = all_articles['articles']
for article in articles[:10]:   
    count+=1
    print(str(count) + ". " 
    + "\n\t\t" + article["summary"]\
    + "\n\n",
    file=open("CNN_Election.txt", "a"))
    time.sleep(0.33)